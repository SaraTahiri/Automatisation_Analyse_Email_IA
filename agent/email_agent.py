"""
Agent IA Intelligent pour l'analyse d'emails
Phase 4 - PFA : Automatisation de l'analyse de s√©curit√© des emails
"""

import os
import sys
import joblib
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, List, Tuple
import json

# Imports des modules du projet
sys.path.append(os.path.abspath(".."))
from extraction.email_parser import parse_email
from preprocessing.text_preprocessing import clean_text
from features.feature_extraction import extract_all_features


class EmailSecurityAgent:
    """
    Agent IA intelligent pour l'analyse de s√©curit√© des emails
    """
    
    def __init__(self, models_dir: str = "../models"):
        """
        Initialisation de l'agent
        
        Args:
            models_dir: R√©pertoire contenant les mod√®les entra√Æn√©s
        """
        self.models_dir = models_dir
        self.models = {}
        self.scaler = None
        self.selected_features = None
        
        # Chargement des mod√®les
        self._load_models()
        
        # Historique des analyses
        self.history_file = "../data/analysis_history.json"
        self.history = self._load_history()
    
    def _load_models(self):
        """Chargement des mod√®les ML/DL"""
        try:
            print("üîÑ Chargement des mod√®les...")
            
            # Logistic Regression
            self.models['lr'] = joblib.load(
                os.path.join(self.models_dir, 'logistic_regression.pkl')
            )
            
            # Random Forest
            self.models['rf'] = joblib.load(
                os.path.join(self.models_dir, 'random_forest.pkl')
            )
            
            # Deep Learning
            from tensorflow.keras.models import load_model
            self.models['dl'] = load_model(
                os.path.join(self.models_dir, 'deep_learning.h5')
            )
            
            # Scaler et features
            self.scaler = joblib.load(
                os.path.join(self.models_dir, 'scaler.pkl')
            )
            self.selected_features = joblib.load(
                os.path.join(self.models_dir, 'selected_features.pkl')
            )
            
            print("‚úÖ Mod√®les charg√©s avec succ√®s")
            
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement des mod√®les : {e}")
            raise
    
    def _load_history(self) -> List[Dict]:
        """Chargement de l'historique des analyses"""
        if os.path.exists(self.history_file):
            try:
                with open(self.history_file, 'r') as f:
                    return json.load(f)
            except:
                return []
        return []
    
    def _save_history(self):
        """Sauvegarde de l'historique"""
        os.makedirs(os.path.dirname(self.history_file), exist_ok=True)
        with open(self.history_file, 'w') as f:
            json.dump(self.history, f, indent=2, default=str)
    
    def analyze_email(self, email_path: str, model_type: str = 'rf') -> Dict:
        """
        Analyse compl√®te d'un email
        
        Args:
            email_path: Chemin vers le fichier .eml
            model_type: Type de mod√®le ('lr', 'rf', 'dl', 'ensemble')
        
        Returns:
            Dictionnaire avec les r√©sultats de l'analyse
        """
        try:
            # 1. Extraction des donn√©es
            email_data = parse_email(email_path)
            
            # 2. Pr√©traitement
            clean_body = clean_text(email_data['Body_Text'])
            
            # 3. Extraction des features
            features = extract_all_features(email_data, clean_body)
            
            # 4. Pr√©paration pour la pr√©diction
            X = pd.DataFrame([features])[self.selected_features]
            X_scaled = self.scaler.transform(X)
            
            # 5. Pr√©diction
            if model_type == 'ensemble':
                prediction, confidence = self._ensemble_predict(X_scaled)
            else:
                prediction, confidence = self._single_model_predict(
                    X_scaled, model_type
                )
            
            # 6. D√©tection des risques
            risks = self._detect_risks(email_data, features, clean_body)
            
            # 7. Classification
            classification = self._classify_threat(prediction, confidence, risks)
            
            # 8. G√©n√©ration du rapport
            result = {
                'timestamp': datetime.now(),
                'email_path': email_path,
                'email_data': {
                    'from': email_data['From'],
                    'to': email_data['To'],
                    'subject': email_data['Subject'],
                    'date': email_data['Date']
                },
                'prediction': prediction,
                'confidence': float(confidence),
                'classification': classification,
                'risks': risks,
                'features': features,
                'model_used': model_type
            }
            
            # 9. Ajout √† l'historique
            self.history.append(result)
            self._save_history()
            
            return result
            
        except Exception as e:
            print(f"‚ùå Erreur lors de l'analyse : {e}")
            raise
    
    def _single_model_predict(self, X_scaled: np.ndarray, 
                             model_type: str) -> Tuple[int, float]:
        """Pr√©diction avec un seul mod√®le"""
        model = self.models[model_type]
        
        if model_type == 'dl':
            proba = model.predict(X_scaled, verbose=0).flatten()[0]
        else:
            proba = model.predict_proba(X_scaled)[0, 1]
        
        prediction = int(proba > 0.5)
        return prediction, proba
    
    def _ensemble_predict(self, X_scaled: np.ndarray) -> Tuple[int, float]:
        """Pr√©diction par ensemble (moyenne pond√©r√©e)"""
        # Poids pour chaque mod√®le (√† ajuster selon performances)
        weights = {
            'lr': 0.2,
            'rf': 0.5,
            'dl': 0.3
        }
        
        probas = []
        for model_type, weight in weights.items():
            _, proba = self._single_model_predict(X_scaled, model_type)
            probas.append(proba * weight)
        
        final_proba = sum(probas)
        prediction = int(final_proba > 0.5)
        
        return prediction, final_proba
    
    def _detect_risks(self, email_data: Dict, features: Dict, 
                     clean_text: str) -> List[Dict]:
        """
        D√©tection d√©taill√©e des risques
        
        Returns:
            Liste des risques d√©tect√©s avec niveau de s√©v√©rit√©
        """
        risks = []
        
        # 1. V√©rification des protocoles de s√©curit√©
        if not features.get('spf_present'):
            risks.append({
                'type': 'SPF_MISSING',
                'severity': 'HIGH',
                'description': 'Aucune v√©rification SPF d√©tect√©e',
                'recommendation': 'Email peut √™tre usurp√©'
            })
        
        if not features.get('dkim_present'):
            risks.append({
                'type': 'DKIM_MISSING',
                'severity': 'HIGH',
                'description': 'Aucune signature DKIM d√©tect√©e',
                'recommendation': 'Authenticit√© du domaine non v√©rifi√©e'
            })
        
        if not features.get('dmarc_present'):
            risks.append({
                'type': 'DMARC_MISSING',
                'severity': 'MEDIUM',
                'description': 'Aucune politique DMARC d√©tect√©e',
                'recommendation': 'Politique d\'authentification absente'
            })
        
        # 2. V√©rification des mots suspects
        if features.get('suspicious_word_count', 0) > 0:
            risks.append({
                'type': 'SUSPICIOUS_KEYWORDS',
                'severity': 'MEDIUM',
                'description': f"{features['suspicious_word_count']} mots suspects d√©tect√©s",
                'recommendation': 'Contenu potentiellement frauduleux'
            })
        
        # 3. V√©rification des URLs
        if features.get('url_count', 0) > 5:
            risks.append({
                'type': 'MULTIPLE_URLS',
                'severity': 'MEDIUM',
                'description': f"{features['url_count']} URLs d√©tect√©es",
                'recommendation': 'Nombre √©lev√© de liens suspects'
            })
        
        https_ratio = (features.get('https_url_count', 0) / 
                      max(features.get('url_count', 1), 1))
        if features.get('url_count', 0) > 0 and https_ratio < 0.5:
            risks.append({
                'type': 'INSECURE_URLS',
                'severity': 'HIGH',
                'description': 'URLs non s√©curis√©es (HTTP)',
                'recommendation': 'Liens potentiellement malveillants'
            })
        
        # 4. V√©rification des attachments
        if features.get('dangerous_attachment', 0):
            risks.append({
                'type': 'DANGEROUS_ATTACHMENT',
                'severity': 'CRITICAL',
                'description': 'Pi√®ce jointe potentiellement dangereuse',
                'recommendation': 'NE PAS ouvrir la pi√®ce jointe'
            })
        
        # 5. Incoh√©rence From/Reply-To
        email_from = email_data.get('From', '')
        reply_to = email_data.get('Reply-To', '')
        if reply_to and reply_to != email_from:
            risks.append({
                'type': 'FROM_REPLY_MISMATCH',
                'severity': 'HIGH',
                'description': 'Incoh√©rence entre From et Reply-To',
                'recommendation': 'Possible tentative d\'usurpation'
            })
        
        return risks
    
    def _classify_threat(self, prediction: int, confidence: float, 
                        risks: List[Dict]) -> Dict:
        """
        Classification du niveau de menace
        
        Returns:
            Dictionnaire avec classification et recommandation
        """
        if prediction == 0:  # L√©gitime
            if confidence > 0.8:
                return {
                    'label': 'LEGITIMATE',
                    'level': 'SAFE',
                    'color': 'green',
                    'recommendation': 'Email s√ªr',
                    'action': 'ALLOW'
                }
            else:
                return {
                    'label': 'SUSPICIOUS',
                    'level': 'LOW',
                    'color': 'yellow',
                    'recommendation': 'V√©rification manuelle recommand√©e',
                    'action': 'FLAG'
                }
        
        else:  # Malveillant
            # D√©terminer le type de menace
            has_attachment = any(r['type'] == 'DANGEROUS_ATTACHMENT' for r in risks)
            has_urls = any(r['type'] in ['MULTIPLE_URLS', 'INSECURE_URLS'] for r in risks)
            
            if has_attachment:
                threat_type = 'MALWARE'
            elif has_urls:
                threat_type = 'PHISHING'
            else:
                threat_type = 'SPAM'
            
            if confidence > 0.9:
                level = 'CRITICAL'
                color = 'red'
                action = 'BLOCK'
            elif confidence > 0.7:
                level = 'HIGH'
                color = 'orange'
                action = 'QUARANTINE'
            else:
                level = 'MEDIUM'
                color = 'yellow'
                action = 'FLAG'
            
            return {
                'label': threat_type,
                'level': level,
                'color': color,
                'recommendation': f'Menace d√©tect√©e : {threat_type}',
                'action': action
            }
    
    def get_statistics(self) -> Dict:
        """G√©n√©ration des statistiques d'utilisation"""
        if not self.history:
            return {
                'total_analyzed': 0,
                'phishing_detected': 0,
                'legitimate': 0,
                'detection_rate': 0.0
            }
        
        df = pd.DataFrame(self.history)
        
        total = len(df)
        phishing = len(df[df['prediction'] == 1])
        legitimate = len(df[df['prediction'] == 0])
        
        # Top domaines attaquants
        phishing_df = df[df['prediction'] == 1]
        if len(phishing_df) > 0:
            from_addresses = phishing_df['email_data'].apply(
                lambda x: x.get('from', 'Unknown')
            )
            top_domains = from_addresses.value_counts().head(10).to_dict()
        else:
            top_domains = {}
        
        # Tendances temporelles
        df['date'] = pd.to_datetime(df['timestamp'])
        df['date_only'] = df['date'].dt.date
        daily_stats = df.groupby('date_only').agg({
            'prediction': ['count', 'sum']
        }).reset_index()
        
        return {
            'total_analyzed': total,
            'phishing_detected': phishing,
            'legitimate': legitimate,
            'detection_rate': (phishing / total * 100) if total > 0 else 0,
            'top_domains': top_domains,
            'daily_stats': daily_stats.to_dict('records'),
            'avg_confidence': float(df['confidence'].mean()),
            'classification_breakdown': df['classification'].apply(
                lambda x: x['label']
            ).value_counts().to_dict()
        }
    
    def generate_report(self, result: Dict) -> str:
        """
        G√©n√©ration d'un rapport d√©taill√© en format texte
        
        Args:
            result: R√©sultat de l'analyse
        
        Returns:
            Rapport format√© en texte
        """
        report = []
        report.append("=" * 80)
        report.append("RAPPORT D'ANALYSE DE S√âCURIT√â EMAIL")
        report.append("=" * 80)
        report.append("")
        
        # Informations g√©n√©rales
        report.append("üìß INFORMATIONS EMAIL")
        report.append("-" * 80)
        report.append(f"De      : {result['email_data']['from']}")
        report.append(f"√Ä       : {result['email_data']['to']}")
        report.append(f"Sujet   : {result['email_data']['subject']}")
        report.append(f"Date    : {result['email_data']['date']}")
        report.append(f"Analys√© : {result['timestamp']}")
        report.append("")
        
        # Classification
        classification = result['classification']
        report.append("üéØ CLASSIFICATION")
        report.append("-" * 80)
        report.append(f"Type        : {classification['label']}")
        report.append(f"Niveau      : {classification['level']}")
        report.append(f"Confiance   : {result['confidence']:.2%}")
        report.append(f"Recommand√©  : {classification['recommendation']}")
        report.append(f"Action      : {classification['action']}")
        report.append("")
        
        # Risques d√©tect√©s
        risks = result['risks']
        report.append(f"‚ö†Ô∏è  RISQUES D√âTECT√âS ({len(risks)})")
        report.append("-" * 80)
        if risks:
            for i, risk in enumerate(risks, 1):
                report.append(f"{i}. [{risk['severity']}] {risk['type']}")
                report.append(f"   {risk['description']}")
                report.append(f"   ‚Üí {risk['recommendation']}")
                report.append("")
        else:
            report.append("Aucun risque sp√©cifique d√©tect√©")
            report.append("")
        
        # Features techniques
        report.append("üîç ANALYSE TECHNIQUE")
        report.append("-" * 80)
        features = result['features']
        report.append(f"Longueur texte       : {features.get('text_length', 0)} caract√®res")
        report.append(f"Nombre de mots       : {features.get('word_count', 0)}")
        report.append(f"Mots suspects        : {features.get('suspicious_word_count', 0)}")
        report.append(f"URLs d√©tect√©es       : {features.get('url_count', 0)}")
        report.append(f"URLs HTTPS           : {features.get('https_url_count', 0)}")
        report.append(f"SPF pr√©sent          : {'‚úì' if features.get('spf_present') else '‚úó'}")
        report.append(f"DKIM pr√©sent         : {'‚úì' if features.get('dkim_present') else '‚úó'}")
        report.append(f"DMARC pr√©sent        : {'‚úì' if features.get('dmarc_present') else '‚úó'}")
        report.append(f"Pi√®ces jointes       : {features.get('attachment_count', 0)}")
        report.append("")
        
        report.append("=" * 80)
        report.append(f"Rapport g√©n√©r√© par Agent IA - Mod√®le: {result['model_used']}")
        report.append("=" * 80)
        
        return "\n".join(report)


# Test de l'agent si ex√©cut√© directement
if __name__ == "__main__":
    print("ü§ñ Initialisation de l'Agent IA...")
    agent = EmailSecurityAgent()
    
    print("\nüìä Statistiques actuelles :")
    stats = agent.get_statistics()
    print(f"Total analys√© : {stats['total_analyzed']}")
    print(f"Phishing d√©tect√© : {stats['phishing_detected']}")
    print(f"Taux de d√©tection : {stats['detection_rate']:.2f}%")